This project implements and evaluates the Q-Learning
algorithm to solve the Gymnasium Taxi-v3 environment,
a classic Reinforcement Learning (RL) problem
involving navigation, pickup, and drop-off in a constrained
grid world. By training an agent over 10,000
episodes using an Ïµ-greedy strategy and a discrete Qtable,
the study successfully derived an optimal policy.
The trained agent demonstrated highly efficient pathfinding,
completing the task in a low number of steps
and achieving a positive net reward in test episodes. The
results confirm the effectiveness of Q-Learning for solving
small-scale Markov Decision Processes (MDPs)
and included the generation of a visual path for demonstration.
